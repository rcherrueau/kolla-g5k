---
# Note: this playbook relies on `xps` variable. The `xps` variable is
# a list that contains the name of all experimentation. For instance,
# this list is as following for the idle experimentation.
# - idle-cpt20-nfk05
# - idle-cpt20-nfk10
# - idle-cpt20-nfk25
# - idle-cpt20-nfk50
- hosts: all
  tasks:
  - name: The list of experimentation
    debug: var=xps

  - name: Making the results and archives directories
    file: path=/results/archives state=directory

  - name: Getting results from home and put them into /results/archives
    command: "cp /home/{{ item }}.tar.gz /results/archives/"
    args:
      creates: "/results/archives/{{ item }}.tar.gz"
    with_items: "{{ xps }}"

  - name: Extracting experimentation results
    command: "tar -C /results -xzf /results/archives/{{ item }}.tar.gz"
    args:
      creates: "/results/{{ item }}"
    with_items: "{{ xps }}"

  - name: Extracting everything
    shell: "for i in $(ls /results/{{ item }}/*.tar.gz); do tar -C /results/{{ item }} -xzf $i; done"
    with_items: "{{ xps }}"
  
  # workaround the https://github.com/BeyondTheClouds/kolla-g5k/issues/44 for older results
  # It will overwrite the logs from those in _data if this directory exists
  - name: Unnesting directory structure (workaround https://github.com/BeyondTheClouds/kolla-g5k/issues/44)
    shell: "cd /results/{{ item }}/tmp/kolla-logs; [ -d _data ] && cp -r _data/* . || echo 0"
    with_items: "{{ xps }}"

  - name: Extract haproxy logs from to one who holds it
    shell: "cd /results/{{ item }}; for i in $(ls *.tar.gz); do tar -tvzf $i | grep haproxy.log | awk -v x=$i '$3 > 0 {print x}'; done | xargs -n 1 tar -xvzf"
    with_items: "{{ xps }}"

  - name: Fixing permissions
    command: chmod 755 -R /results

  - name: Starting influx container
    docker:
      name: "influx_{{ item.1 }}"
      detach: yes
      image: "tutum/influxdb:0.13"
      state: started
      restart_policy: always
      ports:
        - "{{ 8083 +  item.0 * 100 | int }}:8083"
        - "{{ 18086 +  item.0 * 100 | int }}:8086"
      volumes: "/results/{{ item.1 }}/influx-data:/data"
    with_indexed_items: "{{ xps }}"

  - name: Removing previous grafana container
    docker:
      image: "grafana/grafana:3.1.0"
      name: "grafana"
      state: absent

  - name: Starting grafana container
    docker:
      detach: yes
      image: "grafana/grafana:3.1.0"
      name: "grafana"
      ports: "3000:3000"
      state: started
      restart_policy: always


  - name: Waiting for the grafana service to become available
    wait_for:
      # we use the bridge interface of docker
      # instead of localhost
      # api is accessible on loopback too quickly and isn't ready
      host: "172.17.0.1"
      port: 3000
      state: started
      delay: 2
      timeout: 120

  - name: Installing httplib2 library. Required by uri module
    pip: name=httplib2

  - name: Add the influx cadvisor data source
    uri:
      url: "http://localhost:3000/api/datasources"
      user: admin
      password: admin
      force_basic_auth: yes
      body_format: json
      HEADER_Content-Type: application/json
      method: POST
      # we workaround this issue :
      # https://github.com/ansible/ansible-modules-core/issues/265
      # by adding an empty space at the beginning of the json ...
      body: " { \"name\": \"cadvisor-{{ item.1 }}\", \"type\": \"influxdb\", \"url\": \"http://172.17.0.1:{{ 18086 + item.0 * 100 }}\", \"access\": \"proxy\", \"database\": \"cadvisor\", \"user\": \"root\", \"password\": \"root\", \"isDefault\": true }"
      status_code: 200,500
    with_indexed_items: "{{ xps }}"

  - name: Add the influx collectd data source
    uri:
      url: "http://localhost:3000/api/datasources"
      user: admin
      password: admin
      force_basic_auth: yes
      body_format: json
      HEADER_Content-Type: application/json
      method: POST
      # we workaround this issue :
      # https://github.com/ansible/ansible-modules-core/issues/265
      # by adding an empty space at the beginning of the json ...
      body: " { \"name\": \"collectd-{{ item.1 }}\", \"type\": \"influxdb\", \"url\": \"http://172.17.0.1:{{ 18086 + item.0 * 100 }}\", \"access\": \"proxy\", \"database\": \"collectd\", \"user\": \"root\", \"password\": \"root\", \"isDefault\": true }"
      return_content: yes
      status_code: 200
    with_indexed_items: "{{ xps }}"

  - name: Coping the nginx configuration file
    copy: src="files/nginx.conf" dest="/nginx.conf"

  - name: Removing previous nginx server container
    docker:
      image: "nginx:alpine"
      name: "nginx"
      state: absent

  - name: Starting the nginx server container
    docker:
      detach: yes
      image: "nginx:alpine"
      name: "nginx"
      ports: "80:80"
      restart_policy: always
      volumes:
        - "/results:/usr/share/nginx/html"
        - "/nginx.conf:/etc/nginx/nginx.conf"
      state: started

  - name: Add elasticsearch
    docker:
      detach: yes
      image: elasticsearch
      name: elasticsearch
      ports:
        - "9200:9200"
        - "9300:9300"
      restart_policy: always

  - name: Waiting for elasticsearch to become available
    wait_for:
      # we use the bridge interface of docker
      # instead of localhost
      # api is accessible on loopback too quickly and isn't ready
      host: "172.17.0.1"
      port: 9200
      state: started
      delay: 2
      timeout: 120


  # We use the Type field to differentiate different xps
  # Do not analyse it will ease the analyse through kibana
  #
  - name: Check if heka index exists
    uri :
      url: "http://localhost:9200/heka"
      method: GET
      body_format: json
      status_code: 200,404
    register: index

  - debug: var=index

  - name: Deleting old index
    uri :
      url: "http://localhost:9200/heka"
      method: DELETE
      body_format: json
    when: index.status == 200

  - name: Create the heka index in elasticsearch
    uri :
      url: "http://localhost:9200/heka"
      method: PUT

  # Ansible 1.9.x doesn't seem to be able to load a json
  # and use it in the body of the request properly
  # e.g with ansible 2:
  # body: "{{ lookup('file', 'files/mapping.json') | from_json | to_json}}"
  # body_format: json
  - name: Do not analyse some fields in elasticsearch (see mapping.json)
    uri :
      url: "http://localhost:9200/heka/_mapping/message"
      method: PUT
      body: " { \"properties\": {\"{{ item }}\": {\"type\":\"string\", \"index\": \"not_analyzed\"}}}"
      body_format: json
    with_items: ["Type", "request_id", "tenant_id", "user_id", "programname"]

  - name: Add kibana
    docker:
      detach: yes
      image: kibana
      name: kibana
      links:
        - "elasticsearch:elasticsearch"
      ports:
        - "5601:5601"
      restart_policy: always

  - name: Create heka configuration directory
    file: path=/etc/heka state=directory

  - name: Copying heka config files
    copy: src=files/heka/ dest=/etc/heka/{{ item }}
    with_items: "{{ xps }}"

  - name: Generating heka specific configuration
    template: src=templates/heka-{{ item[0] }}.toml.j2 dest=/etc/heka/{{ item[1] }}/heka-{{ item[0] }}.toml
    with_nested:
      - ["elasticsearch", "openstack", "keystone", "mariadb", "rabbitmq"]
      - "{{ xps }}"

  - name: Add kolla/heka
    docker:
      command: kolla_start
      detach: yes
      image: kolla/centos-binary-heka:2.0.2
      name: "heka-{{ item }}"
      links:
        - "elasticsearch:elasticsearch"
      restart_policy: always
      volumes:
        - "/etc/heka/{{ item }}:/var/lib/kolla/config_files"
        - "/etc/localtime:/etc/localtime:ro"
        - "/results/{{ item }}/tmp/kolla-logs:/var/log/kolla"
        - "heka-{{ item }}:/var/cache/hekad"
        - "heka_socket-{{ item }}:/var/lib/kolla/heka"
        # patch to support custom types
        - "/etc/heka/{{ item }}/lua_decoders/os_openstack_log.lua:/usr/share/heka/lua_decoders/os_openstack_log.lua"
        - "/etc/heka/{{ item }}/lua_decoders/os_keystone_apache_log.lua:/usr/share/heka/lua_decoders/os_keystone_apache_log.lua"
        - "/etc/heka/{{ item }}/lua_decoders/os_mysql_log.lua:/usr/share/heka/lua_decoders/os_mysql_log.lua"
        - "/etc/heka/{{ item }}/lua_decoders/os_rabbitmq_log.lua:/usr/share/heka/lua_decoders/os_rabbitmq_log.lua"
      env:
        SKIP_LOG_SETUP: true
        KOLLA_CONFIG_STRATEGY: COPY_ALWAYS
    with_items: "{{ xps }}"
